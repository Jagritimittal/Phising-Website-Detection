# -*- coding: utf-8 -*-
"""df_graphs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FtSCjKyluq4FZJhX7uJ9jPWp1PFqfnsM

#Loading Dataset
"""

from google.colab import drive
drive.mount("/content/drive")

import pandas as pd
import numpy as np

# Import matplotlib package
import matplotlib.pyplot as plt
df = pd.read_csv("Dataset.csv")
print(df.head())

#analysing the summary of dataset
df.info()

print(df.shape)
print(df.columns)

#The nunique() method returns the number of unique values for each column
print(df.nunique())

df.describe().T

import seaborn as sns
plt.figure(figsize=(15,13))
sns.heatmap(df.corr(), annot = True)

"""Checking class distibution in dataset"""

# Plotting the pie chart for the class distribution in the dataset
import matplotlib.pyplot as plt

class_counts = df['Result'].value_counts()
class_counts.plot(kind='pie', autopct='%1.2f%%')
plt.title("Distribution of Phishing Instances")
plt.show()
#data is almost equally distributed among classes therefore their is no need of stratified sampling

class_counts

"""# Data Preprocessing

Checking for Missing Values
"""

df.isnull().sum()

import matplotlib.pyplot as plt

missing_data = df.isnull().sum().sort_values(ascending=False)
plt.figure(figsize=(10, 5))
plt.bar(missing_data.index, missing_data, color='skyblue')
plt.title("Total Missing Values by Column")
plt.xlabel("Columns")
plt.ylabel("Number of Missing Values")
plt.xticks(rotation=90)
plt.show()

"""Dropping Id column from dataset"""

df.drop(['id'], axis=1, inplace=True)
print(df)

"""#Calculating Classifcation Model accuracy without feature selection

## Splitting dataset into train and test data
"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import confusion_matrix
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)

"""## Using Decision Tree"""

model = DecisionTreeClassifier(criterion="entropy", max_depth=10)
model.fit(X_train, y_train)

from sklearn import tree
text_representation = tree.export_text(model)
print(text_representation)

fig = plt.figure(figsize=(70,70))
_ = tree.plot_tree(model, feature_names=df.columns, class_names='Result',label=all,fontsize=13)

#predicting the target value from the model for the samples
y_test_tree = model.predict(X_test)
y_train_tree = model.predict(X_train)

from sklearn.metrics import accuracy_score , f1_score , recall_score, roc_auc_score , precision_score, roc_curve, auc
from sklearn import metrics
#computing the accuracy of the model performance
acc_train_tree = accuracy_score(y_train,y_train_tree)
acc_test_tree = accuracy_score(y_test,y_test_tree)
acc_precision_tree = precision_score(y_test,y_test_tree)
acc_recall_tree = recall_score(y_test,y_test_tree)
acc_f1_tree = f1_score(y_test,y_test_tree)
acc_roc_tree = roc_auc_score(y_test,y_test_tree)


print("Decision Tree: Accuracy on training Data: {:.3f}".format(acc_train_tree))
print("Decision Tree: Accuracy on test Data: {:.3f}".format(acc_test_tree))
print("Decision Tree: precision on test Data: {:.3f}".format(acc_precision_tree))
print("Decision Tree: recall on test Data: {:.3f}".format(acc_recall_tree))
print("Decision Tree: f1 on test Data: {:.3f}".format(acc_f1_tree))
print("Decision Tree: roc on test Data: {:.3f}".format(acc_roc_tree))

# Creating holders to store the model performance results
ML_Model = []
acc_train = []
acc_test = []
acc_precision = []
acc_recall = []
acc_f1 = []
acc_roc = []

#function to call for storing the results
def storeResultsall(model, a,b,c,d,e,f):
  ML_Model.append(model)
  acc_train.append(round(a, 4))
  acc_test.append(round(b, 4))
  acc_precision.append(round(c, 4))
  acc_recall.append(round(d, 4))
  acc_f1.append(round(e, 4))
  acc_roc.append(round(f, 4))

storeResultsall('Decision Tree', acc_train_tree, acc_test_tree,acc_precision_tree,acc_recall_tree,acc_f1_tree,acc_roc_tree)

print('Accucary:', metrics.accuracy_score(y_test,y_test_tree))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_tree))

"""##Using Random forest classifier"""

# Random Forest model
from sklearn.ensemble import RandomForestClassifier

# instantiate the model
forest = RandomForestClassifier(max_depth=10)

# fit the model
forest.fit(X_train, y_train)

#predicting the target value from the model for the samples
y_test_forest = forest.predict(X_test)
y_train_forest = forest.predict(X_train)

acc_train_forest = accuracy_score(y_train,y_train_forest)
acc_test_forest = accuracy_score(y_test,y_test_forest)
acc_precision_forest = precision_score(y_test,y_test_forest)
acc_recall_forest = recall_score(y_test,y_test_forest)
acc_f1_forest = f1_score(y_test,y_test_forest)
acc_roc_forest = roc_auc_score(y_test,y_test_forest)


print("Random forest: Accuracy on training Data: {:.3f}".format(acc_train_forest))
print("Random forest: Accuracy on test Data: {:.3f}".format(acc_test_forest))
print("Random forest: precision on test Data: {:.3f}".format(acc_precision_forest))
print("Random forest: recall on test Data: {:.3f}".format(acc_recall_forest))
print("Random forest: f1 on test Data: {:.3f}".format(acc_f1_forest))
print("Random forest: roc on test Data: {:.3f}".format(acc_roc_forest))

print('Accucary:', metrics.accuracy_score(y_test,y_test_forest))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_forest))

storeResultsall('Random Forest', acc_train_forest, acc_test_forest,acc_precision_forest,acc_recall_forest,acc_f1_forest,acc_roc_forest)

"""## Using Naive Bayes Classifier"""

# Naive Bayes Classifier Model
from sklearn.naive_bayes import GaussianNB

# instantiate the model
nb=  GaussianNB()

# fit the model
nb.fit(X_train,y_train)

y_train_nb = nb.predict(X_train)
y_test_nb = nb.predict(X_test)

acc_train_nb = accuracy_score(y_train,y_train_nb)
acc_test_nb = accuracy_score(y_test,y_test_nb)
acc_precision_nb = precision_score(y_test,y_test_nb)
acc_recall_nb = recall_score(y_test,y_test_nb)
acc_f1_nb = f1_score(y_test,y_test_nb)
acc_roc_nb = roc_auc_score(y_test,y_test_nb)


print("Naive Bayes: Accuracy on training Data: {:.3f}".format(acc_train_nb))
print("Naive Bayes: Accuracy on test Data: {:.3f}".format(acc_test_nb))
print("Naive Bayes: precision on test Data: {:.3f}".format(acc_precision_nb))
print("Naive Bayes: recall on test Data: {:.3f}".format(acc_recall_nb))
print("Naive Bayes: f1 on test Data: {:.3f}".format(acc_f1_nb))
print("Naive Bayes: roc on test Data: {:.3f}".format(acc_roc_nb))

storeResultsall('Naive Bayes', acc_train_nb, acc_test_nb,acc_precision_nb,acc_recall_nb,acc_f1_nb,acc_roc_nb)

print('Accucary:', metrics.accuracy_score(y_test,y_test_nb))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_nb))

"""##Using XGBoostClassifier"""

from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
#le = LabelEncoder()
#Encode target labels with value between 0 and n_classes-1.
#This transformer should be used to encode target values, i.e. y, and not the input X
#y_train = le.fit_transform(y_train)
xgb = XGBClassifier(learning_rate=0.01,max_depth=4)
y_train.replace(to_replace=-1,value=0,inplace=True)
#print(y_train)
y_test.replace(to_replace=-1,value=0,inplace=True)
#print(y_test)
xgb.fit(X_train, y_train)

#predicting the target value from the model for the samples
y_test_xgb = xgb.predict(X_test)
print("y_test_xgb",y_test_xgb)
y_train_xgb = xgb.predict(X_train)
print("y_train_xgb",y_train_xgb)
print(np.unique(y_test_xgb))
print(np.unique(y_test))

acc_train_xgb = accuracy_score(y_train,y_train_xgb)
acc_test_xgb = accuracy_score(y_test,y_test_xgb)
acc_precision_xgb = precision_score(y_test,y_test_xgb)
acc_recall_xgb = recall_score(y_test,y_test_xgb)
acc_f1_xgb = f1_score(y_test,y_test_xgb)
acc_roc_xgb = roc_auc_score(y_test,y_test_xgb)
print("XGBoost: Accuracy on training Data: {:.3f}".format(acc_train_xgb))
print("XGBoost: Accuracy on test Data: {:.3f}".format(acc_test_xgb))
print("XGBoost: precision on test Data: {:.3f}".format(acc_precision_xgb))
print("XGBoost: recall on test Data: {:.3f}".format(acc_recall_xgb))
print("XGBoost: f1 on test Data: {:.3f}".format(acc_f1_xgb))
print("XGBoost: roc on test Data: {:.3f}".format(acc_roc_xgb))

storeResultsall('XGBoost', acc_train_xgb, acc_test_xgb,acc_precision_xgb,acc_recall_xgb,acc_f1_xgb,acc_roc_xgb)

print('Accucary:', metrics.accuracy_score(y_test,y_test_xgb))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_xgb))

results1 = pd.DataFrame({ 'ML Model': ML_Model,
    'Train Accuracy': acc_train,
    'Test Accuracy': acc_test,
    'Precision': acc_precision,
    'Recall' : acc_recall,
    'f1 score': acc_f1,
    'ROC_AUC': acc_roc,
    'Time': 'old'})

results1

"""# Feature Selection

## Feature Selection using Pearson Correlation

### Calculating correlation between features
"""

#calculating correlation between features
n = len(df.columns)
print("No. of columns ", n)
cormat=df.iloc[: ,:-1].corr()
print(cormat)

plt.figure(figsize=(20,18))
sns.heatmap(cormat, annot=True,cmap=plt.cm.Reds)
print(plt.show())

# with the following function we can select highly correlated features
# it will return the first feature that is correlated with anything other feature
def correlation(dataset, threshold):
    col_corr = set() # Set of all the names of correlated columns initally empty
    corr_matrix = dataset.iloc[: ,:-1].corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if ((abs(corr_matrix.iloc[i, j]) > threshold)):
              #checking for columns with correlation value more than threshold
              colname = corr_matrix.columns[i]  # getting the name of column
              col_corr.add(colname)
    return col_corr

#considering threshold is 0.7
corr_features = correlation(df, 0.7)
print("The correlated features are ",corr_features)

print("The number of correlated features ", len(set(corr_features)))

df.drop(corr_features,axis=1,inplace=True)

print(df.shape)
print(df.columns)

"""### Calculating correlation between features and result"""

corr = df.corr()
corr.head()

corr['class']=abs(corr['Result'])
corr.head()

incCorr=corr.sort_values(by='class',ascending=False)
incCorr.head()

incCorr['class']

df.drop(['Favicon','Iframe'],axis=1,inplace=True)
print(df.columns)
print(len(df.columns))

"""## Feature Selection using Information Gain

Calculating mutual information gain between features and target class column
"""

from sklearn.feature_selection import mutual_info_classif
X = df.iloc[:,:-1]
y = df['Result']
#print(X)
#print(y)
mutual_info = mutual_info_classif(X, y)
print(mutual_info)
mutual_info = pd.Series(mutual_info)
mutual_info.index = X.columns
mutual_info.sort_values(ascending=False)

mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))

#Since for
#URL_Length                     0.000000
#having_At_Symbol               0.000000
#Redirect                       0.000000
#mutual information of above mentioned columns with Result is zero it implies these attributes are independent of result
#therefore removing these attributes
df.drop(columns=["URL_Length" ,"Redirect","having_At_Symbol"],axis=1,inplace=True)

print(df.columns)

print(df.shape)
print(df.columns)

"""##Feature Selection - Dropping Constant Features using variance"""

#removes all low(zero)-variance features
from sklearn.feature_selection import VarianceThreshold
var_thres = VarianceThreshold(threshold=0)
#drop features with variance 0 , remove the features that have the same value in all samples
var_thres.fit(df)

#finding non-constant features
# get_support() returns integer index, of the features selected, features that have value more than threshold are retented
var_thres.get_support(indices=False)

print("Number of features retained ",sum(var_thres.get_support()))
#no constant column exist in dataset

"""#Applying Classification Models on selected features

Splitting dataset into train and test data
"""

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn import metrics
from sklearn.metrics import confusion_matrix
X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)

"""## Using Decision Tree Classifier"""

model = DecisionTreeClassifier(criterion="entropy", max_depth=10)
model.fit(X_train, y_train)

from sklearn import tree
text_representation = tree.export_text(model)
print(text_representation)

fig = plt.figure(figsize=(70,70))
_ = tree.plot_tree(model, feature_names=df.columns, class_names='Result',label=all,fontsize=13)

#predicting the target value from the model for the samples
y_test_tree = model.predict(X_test)
y_train_tree = model.predict(X_train)

from sklearn.metrics import accuracy_score , f1_score , recall_score, roc_auc_score , precision_score, roc_curve, auc
from sklearn import metrics
#computing the accuracy of the model performance
acc_train_tree = accuracy_score(y_train,y_train_tree)
acc_test_tree = accuracy_score(y_test,y_test_tree)
acc_precision_tree = precision_score(y_test,y_test_tree)
acc_recall_tree = recall_score(y_test,y_test_tree)
acc_f1_tree = f1_score(y_test,y_test_tree)
acc_roc_tree = roc_auc_score(y_test,y_test_tree)


print("Decision Tree: Accuracy on training Data: {:.3f}".format(acc_train_tree))
print("Decision Tree: Accuracy on test Data: {:.3f}".format(acc_test_tree))
print("Decision Tree: precision on test Data: {:.3f}".format(acc_precision_tree))
print("Decision Tree: recall on test Data: {:.3f}".format(acc_recall_tree))
print("Decision Tree: f1 on test Data: {:.3f}".format(acc_f1_tree))
print("Decision Tree: roc on test Data: {:.3f}".format(acc_roc_tree))

# Creating holders to store the model performance results
ML_Model = []
acc_train = []
acc_test = []
acc_precision = []
acc_recall = []
acc_f1 = []
acc_roc = []

#function to call for storing the results
def storeResults(model, a,b,c,d,e,f):
  ML_Model.append(model)
  acc_train.append(round(a, 4))
  acc_test.append(round(b, 4))
  acc_precision.append(round(c, 4))
  acc_recall.append(round(d, 4))
  acc_f1.append(round(e, 4))
  acc_roc.append(round(f, 4))

storeResults('Decision Tree', acc_train_tree, acc_test_tree,acc_precision_tree,acc_recall_tree,acc_f1_tree,acc_roc_tree)

print('Accucary:', metrics.accuracy_score(y_test,y_test_tree))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_tree))

"""##Using Random Forest Classifier"""

# Random Forest model
from sklearn.ensemble import RandomForestClassifier

# instantiate the model
forest = RandomForestClassifier(max_depth=10)

# fit the model
forest.fit(X_train, y_train)

#predicting the target value from the model for the samples
y_test_forest = forest.predict(X_test)
y_train_forest = forest.predict(X_train)

acc_train_forest = accuracy_score(y_train,y_train_forest)
acc_test_forest = accuracy_score(y_test,y_test_forest)
acc_precision_forest = precision_score(y_test,y_test_forest)
acc_recall_forest = recall_score(y_test,y_test_forest)
acc_f1_forest = f1_score(y_test,y_test_forest)
acc_roc_forest = roc_auc_score(y_test,y_test_forest)


print("Random forest: Accuracy on training Data: {:.3f}".format(acc_train_forest))
print("Random forest: Accuracy on test Data: {:.3f}".format(acc_test_forest))
print("Random forest: precision on test Data: {:.3f}".format(acc_precision_forest))
print("Random forest: recall on test Data: {:.3f}".format(acc_recall_forest))
print("Random forest: f1 on test Data: {:.3f}".format(acc_f1_forest))
print("Random forest: roc on test Data: {:.3f}".format(acc_roc_forest))

print('Accucary:', metrics.accuracy_score(y_test,y_test_forest))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_forest))

storeResults('Random Forest', acc_train_forest, acc_test_forest,acc_precision_forest,acc_recall_forest,acc_f1_forest,acc_roc_forest)

"""##Using Naive Bayes Classifier"""

# Naive Bayes Classifier Model
from sklearn.naive_bayes import GaussianNB

# instantiate the model
nb=  GaussianNB()

# fit the model
nb.fit(X_train,y_train)

y_train_nb = nb.predict(X_train)
y_test_nb = nb.predict(X_test)

acc_train_nb = accuracy_score(y_train,y_train_nb)
acc_test_nb = accuracy_score(y_test,y_test_nb)
acc_precision_nb = precision_score(y_test,y_test_nb)
acc_recall_nb = recall_score(y_test,y_test_nb)
acc_f1_nb = f1_score(y_test,y_test_nb)
acc_roc_nb = roc_auc_score(y_test,y_test_nb)


print("Naive Bayes: Accuracy on training Data: {:.3f}".format(acc_train_nb))
print("Naive Bayes: Accuracy on test Data: {:.3f}".format(acc_test_nb))
print("Naive Bayes: precision on test Data: {:.3f}".format(acc_precision_nb))
print("Naive Bayes: recall on test Data: {:.3f}".format(acc_recall_nb))
print("Naive Bayes: f1 on test Data: {:.3f}".format(acc_f1_nb))
print("Naive Bayes: roc on test Data: {:.3f}".format(acc_roc_nb))

storeResults('Naive Bayes', acc_train_nb, acc_test_nb,acc_precision_nb,acc_recall_nb,acc_f1_nb,acc_roc_nb)

print('Accucary:', metrics.accuracy_score(y_test,y_test_nb))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_nb))

"""## Using XGBoostClassifier"""

from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
#le = LabelEncoder()
#Encode target labels with value between 0 and n_classes-1.
#This transformer should be used to encode target values, i.e. y, and not the input X
#y_train = le.fit_transform(y_train)
xgb = XGBClassifier(learning_rate=0.01,max_depth=4)
y_train.replace(to_replace=-1,value=0,inplace=True)
#print(y_train)
y_test.replace(to_replace=-1,value=0,inplace=True)
#print(y_test)
xgb.fit(X_train, y_train)

#predicting the target value from the model for the samples
y_test_xgb = xgb.predict(X_test)
print("y_test_xgb",y_test_xgb)
y_train_xgb = xgb.predict(X_train)
print("y_train_xgb",y_train_xgb)
print(np.unique(y_test_xgb))
print(np.unique(y_test))

acc_train_xgb = accuracy_score(y_train,y_train_xgb)
acc_test_xgb = accuracy_score(y_test,y_test_xgb)
acc_precision_xgb = precision_score(y_test,y_test_xgb)
acc_recall_xgb = recall_score(y_test,y_test_xgb)
acc_f1_xgb = f1_score(y_test,y_test_xgb)
acc_roc_xgb = roc_auc_score(y_test,y_test_xgb)
print("XGBoost: Accuracy on training Data: {:.3f}".format(acc_train_xgb))
print("XGBoost: Accuracy on test Data: {:.3f}".format(acc_test_xgb))
print("XGBoost: precision on test Data: {:.3f}".format(acc_precision_xgb))
print("XGBoost: recall on test Data: {:.3f}".format(acc_recall_xgb))
print("XGBoost: f1 on test Data: {:.3f}".format(acc_f1_xgb))
print("XGBoost: roc on test Data: {:.3f}".format(acc_roc_xgb))

storeResults('XGBoost', acc_train_xgb, acc_test_xgb,acc_precision_xgb,acc_recall_xgb,acc_f1_xgb,acc_roc_xgb)

print('Accucary:', metrics.accuracy_score(y_test,y_test_xgb))
print('Confusion Matrix\n',metrics.confusion_matrix(y_test,y_test_xgb))

results = pd.DataFrame({ 'ML Model': ML_Model,
    'Train Accuracy': acc_train,
    'Test Accuracy': acc_test,
    'Precision': acc_precision,
    'Recall' : acc_recall,
    'f1 score': acc_f1,
    'ROC_AUC': acc_roc,
    'Time': 'new'})

"""# Comparing Accuracy of various classification models"""

results

results1

results_full = pd.concat([results, results1])
results_full

fig, ax = plt.subplots(1, 3, figsize = (20, 5))

a = sns.barplot(results_full, x = 'ML Model', y = "Train Accuracy", hue = 'Time', ax = ax[0])
b = sns.barplot(results_full, x = 'ML Model', y = "Test Accuracy", hue = 'Time', ax = ax[1])
c = sns.barplot(results_full, x = 'ML Model', y = "ROC_AUC", hue = 'Time', ax = ax[2])